# BERT and Squeeze BERT

## About the Project
Understanding implicit or explicit sentiments conveyed in recent years, Sentiment Anal-
ysis has gained high attention due to its application in understanding public opinion
and social media content which is beneficial to customers, company owners, and other
stakeholders, market research and also sentiment analysis are considered one of the
most significant sub-areas in Natural Language Processing (NLP) research. The tradi-
tional method of sentiment classification, which uses a categorical approach to analyze
text, is only limited to providing binary results as the whole sentiment is positive, neg-
ative, or neutral, which fails to work with complex statements and can only be used
for preliminary analysis. In this paper, we use multi-label sentiment analysis to work
with 28 different emotions covering various human emotions. Along with solving the
primary problem of multi-label classification, we have thoroughly researched the avail-
able NLP classification models and selected the efficient version of the state-of-the-art
classification model BERT called SqueezeBERT, which provides the same prediction
scores with smaller model size and shorter analyzing time which makes it the current
best approach available for smaller devices like laptops and smartphones which do not
have the capabilities of powerful supercomputers but still could achieve state-of-art re-
sults because of heavily pre-trained models.

Keywords: Natural Language Processing(NLP), Bi-directional Encoder Represen-
tation from Transformers (BERT), SqueezeBERT, computer vision, transformers, deep
learning, classification, training time, single-label, multi-label.
